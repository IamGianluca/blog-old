{
  
    
        "post0": {
            "title": "On the benefits of Kaggle",
            "content": "A recent post on Twitter made me realize many don’t notice the actual value Kaggle brings to the larger ML community and Kagglers. . Remember when companies thought their ML innovation would come from external teams competing for cash to build the most accurate model on a test dataset? I&#39;m glad we all learned that using unpaid labor to make models you can&#39;t productionize is bad.WE ALL LEARNED THAT RIGHT? . &mdash; Dr. Jacqueline Nolis (@skyetetra) June 16, 2021 Most media attention focuses on Kaggle GrandMasters and the record-breaking prizes sometimes offered by companies sponsoring those Challenges. The publicity is good but does not give justice to the crucial value-adding contributions of Kaggle. . Before diving into why Kaggle is such a good platform, I want to highlight the value of open competitions ― like the ones organized by Kaggle. . Why are competitions so important? . The recent acceleration of innovation in many ML tasks is primarily motivated by open competition and shared standards. If it weren’t for benchmarks like ImageNet, COCO, and WikiText, the progress in Computer Vision and NLP would have been much slower. Companies and research labs would have continued to invest in research, but we would not be in a state where new SOTA models are released almost weakly. . These open competitions are a positive-sum game for society. Companies and labs don’t need to reinvent the wheel each time. Instead, they can build on top of knowledge shared by others to make progress rapidly. This practice also has other significant impacts on society, thanks to reduced pollution and better affordable AI-driven products. . I can see lots of similarities between the competitions organized by Kaggle and, for instance, the yearly ImageNet challenge. . It’s a free apprenticeship, not unpaid labor . It is hard to deny the positive impact Kaggle had in building a global community of people passionate about ML. It is also hard to deny the number of people who had transitioned to a career in Data Science thanks to what they learned while competing at Kaggle. . While competing with others, Kagglers are learning transferable skills. For instance, the first thing you learn in Kaggle is the value of a robust cross-validation strategy. This skill is critical in the real world. Similarly, after a few competitions, people organically learn how to be effective and good practices, motivated by being competitive with other contestants who have already learned such skills. These skills are hard to acquire in school, bootcamp, or by reading a book. . In this sense, Kaggle is a free apprenticeship led by the community. . A fantastic resource also for experienced scientists . There are also enormous benefits for people that have already established a career in ML. By participating in Kaggle competitions, you can get exposure to ML tasks you don’t face at work and keep up with the SOTA. In addition, constant exposure to best practices and tools allows Kagglers to continuously acquire new skills and get ready for even bigger challenges in the future. . For every Kagglers, the beauty of the platform is not about the Private Leaderboard or the Globa Ranking. Those are just a tool to encourage people to go the extra mile. Kaggle is about learning. . The platform is also rewarding people for sharing good datasets, notebooks, and discussions. I would also argue that many users don’t care about the Leaderboard and Rankings in general. Those are just side effects, and people have real lives. In a sense, it’s like running or any other hobby. Not everyone trains to win the Boston Marathon or the Olympics. Most people run just because it’s a healthy habit. . It’s a level playing field . Not everyone is lucky to work for a leading tech company, surrounded by dozens, if not hundreds, of the best minds in the field. Kaggle lets you learn from some of the very best talents in the industry, even if you live far from where the ML buzz happens. The only limit to your ability to grow is your motivation to try new things, read what others are sharing, and interacting with them. . At the end of each competition, every top-ranked team shares a description of their solution. Sometimes, top-ranked contestants even share the code used to generate their submission. This knowledge-sharing tradition contributes to creating a repository of knowledge everyone can use in future competitions and real-life challenges. Moreover, this knowledge is open to everyone and not hidden behind a paywall. . New SOTA factory and a true benchmark for new models and tools . Nowadays, to be competitive in a Kaggle challenge, it is not sufficient to use out-of-the-box solutions. Instead, competitors often merge ideas from recent research papers or even create entirely new methods later published. . The competition in every Kaggle competition is so fierce that recently released models and tools are immediately tested. This is a great way to gain an understanding of how generalizable are the results of research papers. . Conclusion . In summary, Kaggle is a positive-sum game for society and an excellent investment of your time if you’re interested in becoming a better data scientist and stay up to date. I hope more people join this vibrant and welcoming community. .",
            "url": "https://iamgianluca.github.io/blog/kaggle/community/2021/06/19/the-benefits-of-kaggle.html",
            "relUrl": "/kaggle/community/2021/06/19/the-benefits-of-kaggle.html",
            "date": " • Jun 19, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "How to become a more effective ML/DL practitioner",
            "content": "Intro . This article is aimed to any practitioners that wants to become more effective. This is of course just my opinion, but I hope it will help many people struggling to make the next step in their career. I’ve shared many of this tips over the years and seen the powerful effect they had both on me and others. . Before we start, I’m expecting you to know very well the fundations of Machine Learning. This is necessary prerequisite for anyone working as a Data Scientist or Machine Learning engineer. After you have acquired a good understanding of the fundamentals, there are generally three things that will help you become more productive: . Have an effective development environment | Iterate faster | Continuous learning | . We will see how these themes will come up repeatedly in this article. . Learn how to code . The best investment in your productivity is to learn how to code properly. This means writing code that is reusable and modular. Don’t Repeat Yourself and Keep It Simple (Stupid) should be your guiding principles. . Refactor your code often. Don’t procrastinate when you notice things that can be improved in the codebase. Cruft accumulates rapidly and in no time it will prevent you from iterate quickly. Refactoring is a critical component of the development lifecycle. Don’t neglect that. . Try to be a good boyscout: . Always leave the campground cleaner than you found it. . Your goal is to help your future self. You want to write code once, and reuse it in the future when the need arise. You don’t want to keep reimplementing the same function/class over and over again. You want to go out and accomplish bigger things. . There are two books I often recommend about good software development practices: . “Clean Code” by Robert C. Martin | “Refactoring” by Martin Fowler | . Two key points here are consistency and discipline. You will get there! . Master your tools . As a Machine Learning practitioner, you will spend lots of your time working on a codebase, often connecting to a remote Linux server. There are some tools you must learn how to use well if you want to be effective. These include: . Git | The Linux command line | Docker | . Other tools I often recommend are: . tmux | powerline-shell | dvc | . I would also recommend you to use a dotfiles manager. There are many options out there. Choose one that works for you. Ideally, you would like to install your dotfiles in a new machine with just one command. . I would also recommend you to choose some popular ML libraries and stick to them unless there is a clear advantage in switching to a new one. The software engineering and ML worlds are moving rapidly, and new tools are released seamingly weekly. Your goal is to be effective at build things, not learning how to master the lastest fancy tool. . Become one with your IDE . Mastering your IDE is essential. You will spend lots of time in it. You better be familiar with how to get the best out of it. Learn keybindings and keyboard shortcuts for those operations you do regularly. Learn how to rapidly navigate the codebase ― e.g., jump to definition, rename a symbol, etc. The faster you navigate a project, the quicker you can familiarize with it, implement new features, and fix bugs. . . Additionally, every time you notice a repeated pattern, search how you could automate it. A few minutes per day saved will accumulate and leave you more time to think/work on more valuable problems. . Avoid religious wars about IDEs. Choose what’s best for you and stick to it. I would also recommend you to stay away from people that are too opinionated about IDEs. . Be comfortable with using a debugger . Bugs happen. Being able to interpret error messages and identify the root cause is critical to move fast. Read the error message. Follow the traceback to discover which line is triggering the error. Jump to that line in the codebase and analyze what is wrong. It is really that simple. . Iterate faster . When starting a new project, you need to have a clear plan for making rapid sustainable progress. . Visualize the data . Many practitioners spend too little time familiarizing with the data. They simply load it in a DataLoader and pass it to a model. That might give you the false feeling of moving fast, but moving fast is worthless if you’re going in the wrong direction. . Spend at least a few hours plotting distributions, looking at images, and inspecting outliers. That will give you a good understanding of what problems your model might face, and ultimately guide your progress. . You should not limit yourself to look at the data only at the beginning of a project. Use Error Analysis to understand what model improvement should lead the best return on investment. . Define ML pipeline skeleton . Start by building a skeleton for the ML pipeline. Implement all the necessary steps ― e.g., download, unzip, create cross-validation folds, preprocess, train, predict, post-process ― without worrying too much about the overall solution. Keep things as simple as possible at this stage. Just make sure you have a pipeline you can rapidly improve on. . Cross-validation . Once the initial ML pipeline is ready, it’s time for you to focus on building a robust cross-validation strategy. Rachel Thomas wrote a brilliant blog article about it. I would recommend you to read it, if you haven’t already. . Remember, cross-validation is crucial for making rapid progress. If you don’t have confidence in your validation strategy, you can’t trust the results of your experiments. Even worse, if you cross-validation strategy is flawed, you will have the false impression of making progress. . Choose a good evaluation metric . This is another thing I’ve seen many get wrong. Focus on the ultimate goal. Play around with the evaluation metric and ensure you understand how it behaves ― don’t ignore the corner cases. Is the metric rewarding/penalizing models appropriately to your goal? It would be a waste of time to spend months improving on a metric to discover that it doesn’t align with the business goals. . Sample data . Most of the time, there is no need to use all the available data to test some ideas. Make sure you’re working with enough data to have confidence in the results but little enough to be able to iterate quickly. The faster you iterate, the more ideas you can try, and the more progress you will make. Learning curves help identify a reasonable threshold for how much data you need. . Of course, use all data available when training your final model(s). But for rapid development purposes, if you can get the same answers in half the time, that’s huge. . Start with a simple baseline . Start easy. Don’t jump immediately to the latest fancy model/architecture. Begin with a linear model or even simple frequencies. Once you have established a baseline, try to improve on that. Do it gradually, though. . I’ve seen plenty of colleagues wasting months of work developing a fancy deep learning solution to discover that a simple linear model worked better because of a bug in their codebase. . Be scientific . Too often, I see less experienced practitioners trying things without having a real plan. Make sure you know how to diagnose if your model is underfitting or overfitting, and know how to address that. Formulate hypotheses and run experiments to validate them. If the experiment is not successful, make sure you understand why. That is how you build confidence and lasting knowledge. Don’t try random things in the hope of getting lucky. That is not effective. . . There are massive non-linearities in input and output between top practitioners and the rest of the field. Top practitioners know what to do and why. Being “right” for the wrong reasons does not guarantee long-term success in this profession. You want to understand why something worked or did not. Be honest with yourself. That will pay off in the long term. . One great resource for learning how to be an effective ML practitioner is “Machine Learning Yearning” by Andrew Ng. The book is still under development, but you can get free access to the most recent draft. .",
            "url": "https://iamgianluca.github.io/blog/deep%20learning/machine%20learning/productivity/2021/05/29/effective-ml-dl-practitioner.html",
            "relUrl": "/deep%20learning/machine%20learning/productivity/2021/05/29/effective-ml-dl-practitioner.html",
            "date": " • May 29, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "How to start a career in Data Science",
            "content": "Intro . I’ve been asked this question many times by young practitioners and recent graduates. “What advice would you give to someone starting a career in Data Science?”. . Fall in love with the process . First of all, make sure you have a true passion for Machine Learning. Like in many things, you need to fall in love with the process to ultimately be successful at something. Knowledge and expertise are built day after day and will eventually compound. . You need to be curious and have a genuine interest in understanding how things truly work ― you need to embrace First Principles Thinking. . Take one great online course, then start competing in Kaggle . If you are not sure if Data Science is really something you love, take a semester to complete an excellent online course like fast.ai and work on one or two Kaggle competitions. This should give you first-hand experience of what the job is all about, although not a complete one. . fast.ai’s “Practical Deep Learning for Coders” and “Deep Learning from the Foundations” are excellent courses. They strongly emphasize the practical aspect and teach you good practice in building knowledge and being effective. . . After that, it’s time to get your hands dirty and join Kaggle. Kaggle is a large community of Data Science practitioners. The platform organizes Machine Learning competitions, ranging from Computer Vision to Reinforcement Learning. . . My advice is to not get too distracted by the Public Leaderboard. What you’re interested in is building knowledge. Try to make little progress every day. It’s a long game, and you are here to learn. . Practice over theory . One of the biggest mistakes I’ve seen many beginners make is to spend a disproportionate amount of time studying the theory before beginning to work on their first non-trivial project. This is the wrong way to go about it. The theory is undoubtedly essential, but practice solidifies understanding and makes you ultimately able to build things. This doesn’t mean you shouldn’t spend time learning the theory. Theory and practice should complement each other. . How can you find the right balance between theory and practice? Use your curiosity and First Principle Thinking. Focus on building knowledge. If you don’t understand how something works, don’t be discouraged. Write some code ― see the excellent keynote from John Rauser at Strata + Hadoop 2014 ― or search the internet. Learn as you need and make sure that every new concept sits on a mental map of the space. . Make your project fantastic . To conclude this post, I want to share some advice from Jeremy Howard: . Pick one project. Do it really well. Make it fantastic. . Work on one project at a time, and make sure you’re proud of your work. Leverage everything you have learned so far, refactor it, document it well, and finally share it. . Every one of these projects will be part of your professional portfolio. Make sure your portfolio showcases how great you are! .",
            "url": "https://iamgianluca.github.io/blog/deep%20learning/machine%20learning/advice/2021/05/28/how-to-start-career-in-data-science.html",
            "relUrl": "/deep%20learning/machine%20learning/advice/2021/05/28/how-to-start-career-in-data-science.html",
            "date": " • May 28, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "The easiest way to browse images stored in a remote server",
            "content": "Today, I want to share how you can mount a remote drive locally. This is particularly useful when developing on a remote server. For instance, if we’re working on a computer vision task, we might want to see how some of the training images look. . SSHFS allows you to mount a remote filesystem using SFTP. Most SSH servers support and enable this SFTP access by default, so SSHFS is very simple to use - there’s nothing to do on the server-side. . Let’s first install sshfs. In Ubuntu, you can do it with the following command: . $ sudo apt install sshfs . We need to create an empty directory (a.k.a. mountpoint) to mount the remote drive. Let’s call this folder my_folder: . $ mkdir ~/my_folder . Finally, let’s mount the remote filesystem: . $ sshfs -o follow_symlinks &lt;user&gt;@&lt;server address&gt;:/ ~/my_folder . There you go! When you use your file explorer to open my_folder, you’ll see the remote drive mounted. .",
            "url": "https://iamgianluca.github.io/blog/linux/productivity/2021/05/26/sshfs.html",
            "relUrl": "/linux/productivity/2021/05/26/sshfs.html",
            "date": " • May 26, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi :wave: . My name is Gianluca, and I’m a Data Science Manager based in New York City. . My career in Data Science started in London (UK) in 2013, where I joined a start-up focusing on Real-Time Bidding (RTB) for digital advertising. Since then, many things have changed, and I’ve been fortunate to meet many incredible people who helped me shape who I am. . I’m passionate about ML/DL and how this technology is changing the world. I’m always working on side projects involving ML/DL and learning how things work in my spare time. . My motivations to start blogging are: . Build a bigger platform to share my knowledge and advice. | To quote Richard Feynman, “If you want to master something, teach it.” | Connect with a larger network of like-minded people. | I hope you enjoy the content. If you have any feedback, please reach out to me at my email address: “gr&lt;dot&gt;gianlucarossi&lt;at&gt;gmail&lt;dot&gt;com”. .",
          "url": "https://iamgianluca.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://iamgianluca.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}